{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting our index of extracted mRNA, intron positions\n",
    "\n",
    "> Indexing what we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp training.transcription.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jdb/projects/llm-mito-scanner/venv/lib/python3.10/site-packages/Bio/__init__.py:138: BiopythonWarning: You may be importing Biopython from inside the source tree. This is bad practice and might lead to downstream issues. In particular, you might encounter ImportErrors due to missing compiled C extensions. We recommend that you try running your code from outside the source tree. If you are outside the source tree then you have a setup.py file in an unexpected directory: /home/jdb/projects/llm-mito-scanner/venv/lib/python3.10/site-packages\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "from llm_mito_scanner.data.download import load_config, \\\n",
    "    get_latest_assembly_path, get_genomic_genbank_path\n",
    "\n",
    "random_state = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "config = load_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "data_path = Path(config.get(\"data_path\"))\n",
    "data_raw_path = data_path / \"raw\"\n",
    "assemblies_path = data_raw_path / \"assemblies\"\n",
    "latest_assembly_path = get_latest_assembly_path(assemblies_path)\n",
    "genomic_genbank_path = get_genomic_genbank_path(latest_assembly_path)\n",
    "chromosomes_path = latest_assembly_path / \"chromosomes\"\n",
    "training_data_path = latest_assembly_path / \"training\"\n",
    "transcription_data_path = training_data_path / \"transcription\"\n",
    "intron_locations_path = transcription_data_path / \"intron_positions\"\n",
    "if not intron_locations_path.exists():\n",
    "    raise FileNotFoundError(f\"This notebook requires the path {intron_locations_path.resolve()} to exist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('/mnt/e/Data/llm-mito-scanner-data/data/raw/assemblies/GCF_000001405.40_GRCh38.p14/training/transcription/intron_positions/chromosome-NC_000001.11.parquet'),\n",
       " PosixPath('/mnt/e/Data/llm-mito-scanner-data/data/raw/assemblies/GCF_000001405.40_GRCh38.p14/training/transcription/intron_positions/chromosome-NC_000002.12.parquet'),\n",
       " PosixPath('/mnt/e/Data/llm-mito-scanner-data/data/raw/assemblies/GCF_000001405.40_GRCh38.p14/training/transcription/intron_positions/chromosome-NC_000003.12.parquet')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| hide\n",
    "intron_locations_files = list(intron_locations_path.glob(\"*.parquet\"))\n",
    "intron_locations_files[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geneid</th>\n",
       "      <th>transcriptid</th>\n",
       "      <th>intron_start</th>\n",
       "      <th>intron_end</th>\n",
       "      <th>mrna_start</th>\n",
       "      <th>mrna_end</th>\n",
       "      <th>chromosome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GeneID:79501</td>\n",
       "      <td>NM_001005484.2</td>\n",
       "      <td>15</td>\n",
       "      <td>101</td>\n",
       "      <td>0</td>\n",
       "      <td>6167</td>\n",
       "      <td>NC_000001.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GeneID:79501</td>\n",
       "      <td>NM_001005484.2</td>\n",
       "      <td>155</td>\n",
       "      <td>3618</td>\n",
       "      <td>0</td>\n",
       "      <td>6167</td>\n",
       "      <td>NC_000001.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GeneID:112268260</td>\n",
       "      <td>XM_047436352.1</td>\n",
       "      <td>186</td>\n",
       "      <td>547</td>\n",
       "      <td>0</td>\n",
       "      <td>17102</td>\n",
       "      <td>NC_000001.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GeneID:112268260</td>\n",
       "      <td>XM_047436352.1</td>\n",
       "      <td>1339</td>\n",
       "      <td>2365</td>\n",
       "      <td>0</td>\n",
       "      <td>17102</td>\n",
       "      <td>NC_000001.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GeneID:112268260</td>\n",
       "      <td>XM_047436352.1</td>\n",
       "      <td>2467</td>\n",
       "      <td>8912</td>\n",
       "      <td>0</td>\n",
       "      <td>17102</td>\n",
       "      <td>NC_000001.11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             geneid    transcriptid  intron_start  intron_end  mrna_start   \n",
       "0      GeneID:79501  NM_001005484.2            15         101           0  \\\n",
       "1      GeneID:79501  NM_001005484.2           155        3618           0   \n",
       "2  GeneID:112268260  XM_047436352.1           186         547           0   \n",
       "3  GeneID:112268260  XM_047436352.1          1339        2365           0   \n",
       "4  GeneID:112268260  XM_047436352.1          2467        8912           0   \n",
       "\n",
       "   mrna_end    chromosome  \n",
       "0      6167  NC_000001.11  \n",
       "1      6167  NC_000001.11  \n",
       "2     17102  NC_000001.11  \n",
       "3     17102  NC_000001.11  \n",
       "4     17102  NC_000001.11  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| hide\n",
    "intron_location_frames = []\n",
    "for f in intron_locations_files[:2]:\n",
    "    f_frame = pd.read_parquet(f)\n",
    "    if f_frame.shape[0] > 0:\n",
    "        f_frame.loc[:, 'chromosome'] = f.stem.replace(\"chromosome-\", \"\")\n",
    "        intron_location_frames.append(f_frame)\n",
    "intron_locations = pd.concat(intron_location_frames).reset_index(drop=True)\n",
    "intron_locations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_intron_locations(path: Path) -> pd.DataFrame:\n",
    "    # Index files\n",
    "    chromosome_parquet_files = list(path.glob(\"*.parquet\"))\n",
    "    frames = []\n",
    "    for f in chromosome_parquet_files:\n",
    "        f_frame = pd.read_parquet(f)\n",
    "        if f_frame.shape[0] > 0:\n",
    "            f_frame.loc[:, 'chromosome'] = f.stem.replace(\"chromosome-\", \"\")\n",
    "            frames.append(f_frame)\n",
    "    intron_locations = pd.concat(frames).reset_index(drop=True)\n",
    "    return intron_locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geneid</th>\n",
       "      <th>transcriptid</th>\n",
       "      <th>intron_start</th>\n",
       "      <th>intron_end</th>\n",
       "      <th>mrna_start</th>\n",
       "      <th>mrna_end</th>\n",
       "      <th>chromosome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GeneID:79501</td>\n",
       "      <td>NM_001005484.2</td>\n",
       "      <td>15</td>\n",
       "      <td>101</td>\n",
       "      <td>0</td>\n",
       "      <td>6167</td>\n",
       "      <td>NC_000001.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GeneID:79501</td>\n",
       "      <td>NM_001005484.2</td>\n",
       "      <td>155</td>\n",
       "      <td>3618</td>\n",
       "      <td>0</td>\n",
       "      <td>6167</td>\n",
       "      <td>NC_000001.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GeneID:112268260</td>\n",
       "      <td>XM_047436352.1</td>\n",
       "      <td>186</td>\n",
       "      <td>547</td>\n",
       "      <td>0</td>\n",
       "      <td>17102</td>\n",
       "      <td>NC_000001.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GeneID:112268260</td>\n",
       "      <td>XM_047436352.1</td>\n",
       "      <td>1339</td>\n",
       "      <td>2365</td>\n",
       "      <td>0</td>\n",
       "      <td>17102</td>\n",
       "      <td>NC_000001.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GeneID:112268260</td>\n",
       "      <td>XM_047436352.1</td>\n",
       "      <td>2467</td>\n",
       "      <td>8912</td>\n",
       "      <td>0</td>\n",
       "      <td>17102</td>\n",
       "      <td>NC_000001.11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             geneid    transcriptid  intron_start  intron_end  mrna_start   \n",
       "0      GeneID:79501  NM_001005484.2            15         101           0  \\\n",
       "1      GeneID:79501  NM_001005484.2           155        3618           0   \n",
       "2  GeneID:112268260  XM_047436352.1           186         547           0   \n",
       "3  GeneID:112268260  XM_047436352.1          1339        2365           0   \n",
       "4  GeneID:112268260  XM_047436352.1          2467        8912           0   \n",
       "\n",
       "   mrna_end    chromosome  \n",
       "0      6167  NC_000001.11  \n",
       "1      6167  NC_000001.11  \n",
       "2     17102  NC_000001.11  \n",
       "3     17102  NC_000001.11  \n",
       "4     17102  NC_000001.11  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| hide\n",
    "intron_locations = get_intron_locations(intron_locations_path)\n",
    "intron_locations.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With these locations we can do a few things;\n",
    "\n",
    "1. Get the \"edge\" of the intron and;\n",
    "    1. position the edge at the center, or forward or backward in a training string\n",
    "    2. Wherever the \"edge\" is, replace the gene sequence with the INTRON token on the target string\n",
    "2. Get the \"edge\" of the mRNA and;\n",
    "    1. position the edge at the center, or forward or backward in a training string\n",
    "    2. Wherever the \"edge\" is, replace the gene sequence with the NON-mRNA token on the target string\n",
    "3. Generate training instances that;\n",
    "    1. Include the \"edge\" of the intron with various shifting strategies\n",
    "    2. Exclude the \"edge\" of the intron and get transcribed mRNA\n",
    "    3. Include the \"edge\" of the mRNA with various shifting strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #| export\n",
    "# def make_train_test_split(index: pd.DataFrame, random_state = 42):\n",
    "#     return train_test_split(index, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #| hide\n",
    "# train_idx, test_idx = make_train_test_split(example_training_data_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((983, 6), (328, 6))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# #| hide\n",
    "# train_idx.shape, test_idx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_index</th>\n",
       "      <th>geneid</th>\n",
       "      <th>transcriptid</th>\n",
       "      <th>file</th>\n",
       "      <th>chromosome</th>\n",
       "      <th>partition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1117</th>\n",
       "      <td>172</td>\n",
       "      <td>GeneID:7404</td>\n",
       "      <td>XM_011531441.4</td>\n",
       "      <td>/mnt/e/Data/llm-mito-scanner-data/data/raw/ass...</td>\n",
       "      <td>NC_000024.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>708</th>\n",
       "      <td>708</td>\n",
       "      <td>GeneID:6748</td>\n",
       "      <td>XM_047442389.1</td>\n",
       "      <td>/mnt/e/Data/llm-mito-scanner-data/data/raw/ass...</td>\n",
       "      <td>NC_000023.11</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536</th>\n",
       "      <td>536</td>\n",
       "      <td>GeneID:266740</td>\n",
       "      <td>NM_001321403.1</td>\n",
       "      <td>/mnt/e/Data/llm-mito-scanner-data/data/raw/ass...</td>\n",
       "      <td>NC_000023.11</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>808</th>\n",
       "      <td>808</td>\n",
       "      <td>GeneID:6901</td>\n",
       "      <td>NM_001303465.2</td>\n",
       "      <td>/mnt/e/Data/llm-mito-scanner-data/data/raw/ass...</td>\n",
       "      <td>NC_000023.11</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>682</th>\n",
       "      <td>682</td>\n",
       "      <td>GeneID:139728</td>\n",
       "      <td>NM_001366976.1</td>\n",
       "      <td>/mnt/e/Data/llm-mito-scanner-data/data/raw/ass...</td>\n",
       "      <td>NC_000023.11</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      file_index         geneid    transcriptid   \n",
       "1117         172    GeneID:7404  XM_011531441.4  \\\n",
       "708          708    GeneID:6748  XM_047442389.1   \n",
       "536          536  GeneID:266740  NM_001321403.1   \n",
       "808          808    GeneID:6901  NM_001303465.2   \n",
       "682          682  GeneID:139728  NM_001366976.1   \n",
       "\n",
       "                                                   file    chromosome   \n",
       "1117  /mnt/e/Data/llm-mito-scanner-data/data/raw/ass...  NC_000024.10  \\\n",
       "708   /mnt/e/Data/llm-mito-scanner-data/data/raw/ass...  NC_000023.11   \n",
       "536   /mnt/e/Data/llm-mito-scanner-data/data/raw/ass...  NC_000023.11   \n",
       "808   /mnt/e/Data/llm-mito-scanner-data/data/raw/ass...  NC_000023.11   \n",
       "682   /mnt/e/Data/llm-mito-scanner-data/data/raw/ass...  NC_000023.11   \n",
       "\n",
       "      partition  \n",
       "1117          0  \n",
       "708           7  \n",
       "536           7  \n",
       "808           7  \n",
       "682           7  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# #| hide\n",
    "# train_idx.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #| export\n",
    "# def get_sequence(file: Path, idx: int) -> pd.Series:\n",
    "#     row = pd.read_parquet(file).iloc[idx, :]\n",
    "#     return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #| hide\n",
    "# example_sequence = get_sequence(train_idx.iloc[0, -3], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# #| hide\n",
    "# example_sequence.input.count(\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #| export\n",
    "# class TranscriptionDataset(Dataset):\n",
    "#     def __init__(self, training_path: Path, sequences_path: Path, train: bool):\n",
    "#         self.training_path = training_path\n",
    "#         self.sequences_path = sequences_path\n",
    "#         self.train = train\n",
    "#         self.training_index = get_training_index(self.training_path, self.sequences_path, sample=False, save=True)\n",
    "#         self.train_idx, self.test_idx = make_train_test_split(self.training_index)\n",
    "\n",
    "#     def filter_chromosome(self, chromosome: str):\n",
    "#         index_chromosomes = self.training_index.chromosome.unique()\n",
    "#         if not chromosome in index_chromosomes:\n",
    "#             raise ValueError(f\"Chromosome {chromosome} not found in training data.\")\n",
    "#         filtered_training_index = self.training_index[self.training_index.chromosome == chromosome]\n",
    "#         self.training_index = filtered_training_index\n",
    "#         self.train_idx, self.test_idx = make_train_test_split(self.training_index)\n",
    "\n",
    "#     def __len__(self) -> int:\n",
    "#         if self.train:\n",
    "#             return self.train_idx.shape[0]\n",
    "#         else:\n",
    "#             return self.test_idx.shape[0]\n",
    "\n",
    "#     def __getitem__(self, idx) -> tuple[str, str]:\n",
    "#         if self.train:\n",
    "#             sequence_row = self.train_idx.iloc[idx, :]\n",
    "#         else:\n",
    "#             sequence_row = self.test_idx.iloc[idx, :]\n",
    "#         sequence = get_sequence(sequence_row.file, sequence_row.file_index)\n",
    "#         return sequence.input, sequence.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #| hide\n",
    "# transcription_dataset_train = TranscriptionDataset(transcription_data_path, sequences_data_path, True)\n",
    "# transcription_dataset_test = TranscriptionDataset(transcription_data_path, sequences_data_path, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(97815, 32605)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# #| hide\n",
    "# len(transcription_dataset_train), len(transcription_dataset_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9630, 3211)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# #| hide\n",
    "# transcription_dataset_train.filter_chromosome(\"NC_000001.11\")\n",
    "# transcription_dataset_test.filter_chromosome(\"NC_000001.11\")\n",
    "# len(transcription_dataset_train), len(transcription_dataset_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13415\n",
      "122052\n"
     ]
    }
   ],
   "source": [
    "# #| hide\n",
    "# for i, tup in enumerate(transcription_dataset_train):\n",
    "#     if i == 2:\n",
    "#         break\n",
    "#     print(tup[0].count(\",\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #| export\n",
    "# def tokenize(seq: str) -> list[str]:\n",
    "#     return seq.split(\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #| hide\n",
    "# sample_train_data = transcription_dataset_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13416, 13416)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# #| hide\n",
    "# len(tokenize(sample_train_data[0])), len(tokenize(sample_train_data[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# #| hide\n",
    "# gene_path = latest_assembly_path / \"genes\"\n",
    "# gene_path.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'C': 1, 'D': 1})"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# #| hide\n",
    "# Counter(\"C,D\".split(\",\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #| export\n",
    "# def count_transcription_tokens(parquet_path: Path) -> Counter:\n",
    "#     token_counter = Counter()\n",
    "#     sequences = pd.read_parquet(parquet_path, columns=['input', 'target'])\n",
    "#     input_counter = sum(sequences.input.apply(tokenize).apply(Counter).values.tolist(), Counter())\n",
    "#     target_counter = sum(sequences.target.apply(tokenize).apply(Counter).values.tolist(), Counter())\n",
    "#     token_counter = input_counter + target_counter\n",
    "#     return token_counter\n",
    "\n",
    "\n",
    "# UNK_TOKEN = \"<unk>\"\n",
    "# PAD_TOKEN = \"<pad>\"\n",
    "# BOS_TOKEN = \"<bos>\"\n",
    "# EOS_TOKEN = \"<eos>\"\n",
    "# SPECIAL_TOKENS = [\n",
    "#     UNK_TOKEN,\n",
    "#     PAD_TOKEN,\n",
    "#     BOS_TOKEN,\n",
    "#     EOS_TOKEN\n",
    "# ]\n",
    "\n",
    "\n",
    "# def build_vocab(\n",
    "#         parquet_files: list[Path], \n",
    "#         special_tokens: list[str] = SPECIAL_TOKENS,\n",
    "#         unknown_token: str = UNK_TOKEN):\n",
    "#     counter = Counter()\n",
    "#     max_processes = min(8, os.cpu_count() - 1)\n",
    "#     pool = Pool(\n",
    "#         processes=min(max_processes, len(parquet_files)))\n",
    "#     try:\n",
    "#         pbar = tqdm(total=len(parquet_files), leave=False)\n",
    "#         for c in pool.imap_unordered(count_transcription_tokens, parquet_files):\n",
    "#             counter = counter + c\n",
    "#             pbar.update(1)\n",
    "#     except Exception as e:\n",
    "#         raise e\n",
    "#     finally:\n",
    "#         pbar.close()\n",
    "#         pool.close()\n",
    "#     token_ordered_dict = OrderedDict(counter.most_common())\n",
    "#     transcription_vocab = vocab(token_ordered_dict, specials=special_tokens, special_first=True)\n",
    "#     unk_index = transcription_vocab[unknown_token]\n",
    "#     transcription_vocab.set_default_index(unk_index)\n",
    "#     return transcription_vocab\n",
    "\n",
    "\n",
    "# def get_vocab(\n",
    "#         training_path: Path,\n",
    "#         force_build: bool = False,\n",
    "#         save: bool = True,\n",
    "#         **build_vocab_kwargs\n",
    "#         ) -> Vocab:\n",
    "#     vocab_path = training_path / \"vocab.pt\"\n",
    "#     if not vocab_path.exists() or force_build:\n",
    "#         transcription_vocab = build_vocab(**build_vocab_kwargs)\n",
    "#         if save:\n",
    "#             torch.save(transcription_vocab, vocab_path)\n",
    "#     else:\n",
    "#         transcription_vocab = torch.load(vocab_path)\n",
    "#     return transcription_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                             \r"
     ]
    }
   ],
   "source": [
    "# #| hide\n",
    "# example_transcription_vocab = get_vocab(\n",
    "#     transcription_data_path, \n",
    "#     force_build=True, \n",
    "#     save=False,\n",
    "#     parquet_files=chromosome_parquet_files[-2:]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# #| hide\n",
    "# len(example_transcription_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<unk>', '<pad>', '<bos>', '<eos>', '<intron>', 'T', 'A', 'G', 'C']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# #| hide\n",
    "# example_transcription_vocab.lookup_tokens(list(range(0, len(example_transcription_vocab))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #| export\n",
    "# def process_training_sequence(sequence: tuple[str, str], data_vocab: Vocab) -> tuple[Tensor, Tensor]:\n",
    "#     \"\"\"Converts raw text into a flat Tensor.\"\"\"\n",
    "#     input_tensor = torch.tensor(data_vocab(tokenize(sequence[0])), dtype=torch.long)\n",
    "#     target_tensor = torch.tensor(data_vocab(tokenize(sequence[1])), dtype=torch.long)\n",
    "#     return input_tensor, target_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([7, 5, 7,  ..., 7, 6, 6]), tensor([7, 5, 7,  ..., 7, 6, 6]))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# #| hide\n",
    "# processed_example_sequence = process_training_sequence(sample_train_data, example_transcription_vocab)\n",
    "# processed_example_sequence[0], processed_example_sequence[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([13416])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# #| hide\n",
    "# processed_example_sequence[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# #| hide\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #| export\n",
    "# def batchify_sequence(sequence: Tensor, bsz: int) -> Tensor:\n",
    "#     global device\n",
    "#     seq_len = sequence.size(0) // bsz\n",
    "#     data = sequence[:seq_len * bsz]\n",
    "#     data = data.view(bsz, seq_len).t().contiguous()\n",
    "#     return data.to(device)\n",
    "\n",
    "\n",
    "# def batchify(sequence_tensors: tuple[Tensor, Tensor], bsz: int) -> tuple[Tensor, Tensor]:\n",
    "#     \"\"\"Divides the data into ``bsz`` separate sequences, removing extra elements\n",
    "#     that wouldn't cleanly fit.\n",
    "\n",
    "#     Arguments:\n",
    "#         data: Tensor, shape ``[N]``\n",
    "#         bsz: int, batch size\n",
    "\n",
    "#     Returns:\n",
    "#         Tensor of shape ``[N // bsz, bsz]``\n",
    "#     \"\"\"\n",
    "#     input_batches = batchify_sequence(sequence_tensors[0], bsz)\n",
    "#     target_batches = batchify_sequence(sequence_tensors[1], bsz)\n",
    "#     return input_batches, target_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #| hide\n",
    "# batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #| export\n",
    "# def get_batch(input: Tensor, target: Tensor, i: int, bptt: int = 35) -> tuple[Tensor, Tensor]:\n",
    "#     global device\n",
    "#     seq_len = min(bptt, len(input) - 1 - i)\n",
    "#     data = input[i:i+seq_len].to(device)\n",
    "#     target = target[i:i+seq_len].to(device)\n",
    "#     return data, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #| hide\n",
    "# bptt = 35\n",
    "# eval_batch_size = 10\n",
    "\n",
    "# processed_example_sequence_input, processed_example_sequence_target = processed_example_sequence\n",
    "# sequences_batch_num = (processed_example_sequence_input.shape[0] - 1) // bptt\n",
    "# for batch, i in enumerate(range(0, sequences_batch_num, bptt)):\n",
    "#     # Get Batch\n",
    "#     data, target = get_batch(processed_example_sequence_input, processed_example_sequence_target, i, bptt)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "383\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([7, 5, 7, 8, 7, 7, 6, 7, 5, 5, 5, 7, 7, 8, 5, 7, 8, 5, 8, 8, 7, 7, 7, 7,\n",
       "         5, 5, 6, 7, 8, 6, 7, 7, 5, 7, 6], device='cuda:0'),\n",
       " tensor([7, 5, 7, 8, 7, 7, 6, 7, 5, 5, 5, 7, 7, 8, 5, 7, 8, 5, 8, 8, 7, 7, 7, 7,\n",
       "         5, 5, 6, 7, 8, 6, 7, 7, 5, 7, 6], device='cuda:0'),\n",
       " torch.Size([35]),\n",
       " torch.Size([35]))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# #| hide\n",
    "# print(sequences_batch_num)\n",
    "# data, target, data.shape, target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
